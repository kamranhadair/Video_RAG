# ğŸ¥ Video RAG - Chat with YouTube Videos

A production-ready Retrieval-Augmented Generation (RAG) system for conversational Q&A over YouTube videos with LangGraph orchestration.

## âœ¨ Features

- ğŸ¬ **YouTube Integration**: Download and process any YouTube video
- ğŸ¤ **Whisper Transcription**: Accurate speech-to-text with timestamps
- ğŸ” **Semantic Search**: FAISS vector store with cosine similarity
- ğŸ¤– **LangGraph Workflow**: Multi-agent orchestration with intent routing
- ğŸ’¬ **Conversation Memory**: Multi-turn conversations with context
- âœ… **Answer Validation**: Confidence scoring and quality checks
- ğŸ“ **Source Attribution**: Timestamp-preserved citations
- ğŸš€ **Production Ready**: Clean, tested, and deployable

## ğŸ—ï¸ Architecture

```
User Query
    â†“
Query Analyzer (Intent Classification)
    â†“
Retrieval Agent (Semantic Search)
    â†“
Answer Generator (LLM Synthesis)
    â†“
Validator Agent (Quality Check)
    â†“
Response with Confidence & Sources
```

## ğŸ“‹ Prerequisites

- Python 3.9+
- FFmpeg (included in `bin/` directory)
- Groq API key (or Ollama for local inference)

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
git clone https://github.com/yourusername/Video_RAG.git
cd Video_RAG
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

### 3. Run the App

```bash
streamlit run frontend/app.py
```

Open http://localhost:8501 in your browser.

## ğŸ’¡ Usage

### Web Interface (Recommended)

1. Enter a YouTube URL in the sidebar
2. Click "Process Video"
3. Wait for processing (2-5 minutes depending on video length)
4. Ask questions in the chat interface

### Python API

```python
from backend.services import VideoRAGService

service = VideoRAGService()

# Process a video
video_id = service.ingest_video("https://www.youtube.com/watch?v=...")

# Query the video
response = service.query(video_id, "What is this video about?", use_langgraph=True)
print(response.answer)
print(response.sources)
```

### With Conversation Memory

```python
from backend.utils.conversation_memory import ConversationMemory

memory = ConversationMemory()

# First turn
r1 = service.query(video_id, "What's the main topic?")
memory.add_turn("What's the main topic?", r1.answer)

# Second turn (with context)
r2 = service.query(video_id, "Tell me more about that")
memory.add_turn("Tell me more about that", r2.answer)
```

## ğŸ“ Project Structure

```
Video_RAG/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/                 # LangGraph agents
â”‚   â”‚   â”œâ”€â”€ query_analyzer.py   # Intent classification
â”‚   â”‚   â”œâ”€â”€ retrieval_agent.py  # Semantic search
â”‚   â”‚   â”œâ”€â”€ answer_generator.py # Answer synthesis
â”‚   â”‚   â””â”€â”€ validator_agent.py  # Quality validation
â”‚   â”œâ”€â”€ workflows/              # LangGraph workflows
â”‚   â”‚   â””â”€â”€ rag_graph.py        # Main orchestration
â”‚   â”œâ”€â”€ core/                   # Core components
â”‚   â”‚   â”œâ”€â”€ video_downloader.py # YouTube audio extraction
â”‚   â”‚   â”œâ”€â”€ transcriber.py      # Whisper transcription
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Semantic chunking
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # FAISS indexing
â”‚   â”‚   â””â”€â”€ llm_adapter.py      # LLM abstraction
â”‚   â”œâ”€â”€ services/               # Service layer
â”‚   â”‚   â”œâ”€â”€ video_rag_service.py # Main facade
â”‚   â”‚   â””â”€â”€ rag_pipeline.py     # Legacy pipeline
â”‚   â”œâ”€â”€ models/                 # Data models
â”‚   â”‚   â”œâ”€â”€ document.py         # Chunk, Metadata
â”‚   â”‚   â””â”€â”€ rag_state.py        # LangGraph state
â”‚   â”œâ”€â”€ utils/                  # Utilities
â”‚   â”‚   â””â”€â”€ conversation_memory.py # Multi-turn support
â”‚   â””â”€â”€ config.py               # Configuration
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ data/                       # Generated at runtime
â”‚   â”œâ”€â”€ faiss_indexes/          # Vector indices
â”‚   â”œâ”€â”€ metadata/               # Video metadata
â”‚   â””â”€â”€ cache/                  # Audio files
â”œâ”€â”€ bin/                        # FFmpeg binaries
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `.env` to customize:

```env
# LLM Provider
LLM_PROVIDER=groq              # groq | ollama
GROQ_API_KEY=your_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Whisper Model
WHISPER_MODEL=base             # tiny | base | small | medium | large
WHISPER_DEVICE=cpu             # cpu | cuda

# Chunking
CHUNK_SIZE=500                 # tokens
CHUNK_OVERLAP=100              # tokens

# Retrieval
TOP_K_RETRIEVAL=5
SIMILARITY_THRESHOLD=0.2
MAX_CONTEXT_LENGTH=4000
```

## ğŸ¯ Key Components

### Query Analyzer
Classifies query intent (qa, summary, comparison) for intelligent routing.

### Retrieval Agent
Performs semantic search using FAISS with confidence scoring.

### Answer Generator
Synthesizes answers using LLM with strict anti-hallucination prompts.

### Validator Agent
Checks answer quality and assigns confidence scores.

## ğŸ“Š Performance

- **Query Processing**: ~2 seconds
- **Video Processing**: 2-5 minutes (depends on length and model)
- **Confidence Scoring**: Per-answer quality metrics
- **Multi-turn Support**: Full conversation history

## ğŸ” Security

- API keys stored in `.env` (never committed)
- Input validation on YouTube URLs
- No external API calls except LLM provider
- Local FAISS indices (no cloud storage)

## ğŸ“š Documentation

- **ENGINEERING_NOTES.md**: Design decisions and trade-offs
- **CONTRIBUTING.md**: Contribution guidelines

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- OpenAI Whisper for transcription
- Facebook AI Research for FAISS
- Sentence Transformers community
- Groq for fast inference
- LangChain/LangGraph teams

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue.

---

**Status**: âœ… Production Ready | LangGraph v1 | Tested with multiple videos
